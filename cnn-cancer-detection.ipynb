{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Building CNN From Scratch With Keras For Cancer Detection\n***By Kris Smith***","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np, pandas as pd, tensorflow as tf\nimport os\nimport cv2\nfrom PIL import Image \nfrom glob import glob \nfrom keras.callbacks import *\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import *\nfrom keras.layers.normalization import *\nfrom keras.layers.convolutional import *\nfrom keras.layers.core import *\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread\n%matplotlib inline\n\n\nprint(os.listdir(\"../input/histopathologic-cancer-detection\"))\n\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n#############################################################\n\n\n\n\n# import os, cv2\n# from scipy import stats\n\n# from tqdm import tqdm_notebook,trange\n\n# from time import time\n\n# from sklearn.model_selection import train_test_split\n\n# from keras.applications.vgg16 import VGG16\n\n# from keras.callbacks import TensorBoard\n\n# # import the necessary packages\n# from keras.models import Sequential\n# # from keras.layers.normalization import BatchNormalization\n# from keras.layers.convolutional import Conv2D\n# from keras.layers.convolutional import MaxPooling2D\n# from keras.layers.core import Activation\n# from keras.layers.core import Flatten\n# from keras.layers.core import Dropout\n# from keras.layers.core import Dense\n# from keras import backend as K","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# EDA","metadata":{}},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"print(f'Total Number of Samples in Training Data = {len(os.listdir(\"../input/histopathologic-cancer-detection/train\"))}')\nprint(f'Total Number of Samples in Test Data = {len(os.listdir(\"../input/histopathologic-cancer-detection/test\"))}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/histopathologic-cancer-detection/\"\ntrain_path = path + 'train/'\ntest_path = path + 'test/'\n\n### Read data into pandas frames ###\n## Load training and testing file names into frames\ndf = pd.DataFrame({'path': glob(os.path.join(train_path,'*.tif'))}) \ndf_test = pd.DataFrame({'path': glob(os.path.join(test_path,'*.tif'))}) \n\n## Isolate the id from file names and store as id features in seperate column\ndf['id'] = df.path.map(lambda x: x.split('/')[4].split(\".\")[0]) \n\n## Read in training labels\nlabels = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\n\n## Add Labels to training data \ndf = df.merge(labels, on = \"id\") # merge labels and filepaths\ndf.sample(7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets Inspect Distribution Among The Classes in Training Data","metadata":{}},{"cell_type":"code","source":"labels['label'].value_counts().plot(kind='barh', title='Class Distribution in Training Data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inspect Some Samples From Both Positive and Negative Classes","metadata":{}},{"cell_type":"code","source":"## Filter dataframe to get a subset of each class\nclass0 = df[df['label'] == 0]\nclass1 = df[df['label'] == 1]\n\nfor image in range(5):\n    ## Select a random sample from each class\n    sample0 = class0.sample(1)\n    sample1 = class1.sample(1)\n\n    ## Open image files and plot\n    img_path0 = sample0['path'].values[0]\n    img_path1 = sample1['path'].values[0]\n\n    img0 = Image.open(img_path0)\n    img1 = Image.open(img_path1)\n\n    fig, ax = plt.subplots(1, 2, figsize=(5, 2))\n\n    ax[0].imshow(img0)\n    ax[0].set_title('Class 0')\n    ax[0].axis('off')\n\n    ax[1].imshow(img1)\n    ax[1].set_title('Class 1')\n    ax[1].axis('off')\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Apparently metastatic cells should appear a different size, shape, or pattern compared to the cells around them. Inspecting these images I am realizing that I am not a medical professional and therefore I can see no obvious differences between the positive and negative class images. Therefore I will be relying on the labels and the model to distinguish between the two.***","metadata":{}},{"cell_type":"markdown","source":"---\n# Training","metadata":{}},{"cell_type":"markdown","source":"## Split Training Data","metadata":{}},{"cell_type":"code","source":"# !pip install git+https://github.com/keras-team/keras-preprocessing.git\ndf = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\n# df = df.sample(12800)\n\ndf['label'] = df['label'].astype(str)\n# df = df.sample(640)\n\ndef append_ext(ID):\n    return(ID+\".tif\")\n\n\ndf[\"id\"] = df[\"id\"].apply(append_ext)\n\n\n\ntrain_datagen = ImageDataGenerator(\n       horizontal_flip=True,\n       vertical_flip=True,\n       #brightness_range=[0.5, 1.5],\n       #fill_mode='reflect',                               \n        rotation_range=15,\n        rescale=1./255,\n        #shear_range=0.2,\n        #zoom_range=0.2\n        validation_split=0.10\n    \n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_path = '../input/histopathologic-cancer-detection/train'\nvalid_path = '../input/histopathologic-cancer-detection/train'\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                dataframe=df,\n                directory=train_path,\n                x_col = 'id',\n                y_col = 'label',\n#                 has_ext=True,\n                subset='training',\n                target_size=(96, 96),\n                batch_size=16,\n                class_mode='binary'\n                )\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n                dataframe=df,\n                directory=valid_path,\n                x_col = 'id',\n                y_col = 'label',\n#                 has_ext=True,\n                subset='validation', \n                target_size=(96, 96),\n                batch_size=16,\n                shuffle=False,\n                class_mode='binary'\n                )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Model Architecture","metadata":{}},{"cell_type":"markdown","source":"### Model 1","metadata":{}},{"cell_type":"code","source":"# with tf.device('/gpu:0'):  \n#     model = Sequential()\n    \n#     model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\n#     model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Dropout(0.3))\n#     model.add(MaxPooling2D(pool_size = 3))\n\n#     model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Dropout(0.3))\n#     model.add(MaxPooling2D(pool_size = 3))\n\n#     model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Dropout(0.3))\n#     model.add(MaxPooling2D(pool_size = 3))\n\n#     model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n#     model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n#     model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n#     model.add(Dropout(0.3))\n\n#     model.add(Flatten())\n#     model.add(Dense(128, activation='relu'))\n#     model.add(Dropout(0.3))\n#     model.add(Dense(1, activation = 'sigmoid'))\n# #     model.summary()\n\n#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n#     STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n#     STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n\n#     history = model.fit(train_generator,\n#                         steps_per_epoch=STEP_SIZE_TRAIN,\n#                         epochs=15,\n#                         validation_data=validation_generator,\n#                         validation_steps=STEP_SIZE_VALID)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2","metadata":{}},{"cell_type":"code","source":"with tf.device('/gpu:0'):  \n    model = Sequential()\n    \n    model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\n#     model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n    model.add(Dropout(0.3))\n    model.add(MaxPooling2D(pool_size = 3))\n\n    model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n    model.add(Dropout(0.3))\n    model.add(MaxPooling2D(pool_size = 3))\n\n    model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n#     model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n    model.add(Dropout(0.3))\n    model.add(MaxPooling2D(pool_size = 3))\n\n    model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n#     model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n#     model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(1, activation = 'sigmoid'))\n#     model.summary()\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n    STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n\n    history = model.fit(train_generator,\n                        steps_per_epoch=STEP_SIZE_TRAIN,\n                        epochs=10,\n                        validation_data=validation_generator,\n                        validation_steps=STEP_SIZE_VALID)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 3","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model.evaluate_generator(generator=validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\nmodel.save('Keras_CNN_3.h5')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Returns a compiled model identical to the previous one\nmodel = load_model('/kaggle/working/Keras_CNN_3.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(path + 'sample_submission.csv')\n\nTESTING_BATCH_SIZE = 64\ntesting_files = glob(os.path.join(test_path,'*.tif'))\nsubmission = pd.DataFrame()\nprint(len(testing_files))\nfor index in range(0, len(testing_files), TESTING_BATCH_SIZE):\n    data_frame = pd.DataFrame({'path': testing_files[index:index+TESTING_BATCH_SIZE]})\n    data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[4].split(\".\")[0])\n    data_frame['image'] = data_frame['path'].map(imread)\n    images = np.stack(data_frame.image, axis=0)\n    predicted_labels = [model.predict(np.expand_dims(image/255.0, axis=0))[0][0] for image in images]\n    predictions = np.array(predicted_labels)\n    data_frame['label'] = predictions\n    submission = pd.concat([submission, data_frame[[\"id\", \"label\"]]])\n#     if index % 1000 == 0 :\n#         print(index/len(testing_files) * 100)\nsubmission.to_csv('submission.csv', index=False, header=True)\nprint(submission.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(submission))\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}